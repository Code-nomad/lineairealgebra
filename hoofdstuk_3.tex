\documentclass[lineaire_algebra_oplossingen.tex]{subfiles}
\begin{document}

\chapter{Hoofdstuk 3}
\section{Bewijzen uit het boek}
\subsection{Lemma 3.7 p 93}
Zij $(\mathbb{R},V,+)$ een vectorruimte en $v,w,x\in V$
\subsubsection*{Te Bewijzen}
\[
v+x = w+x \Rightarrow v=w
\]
\subsubsection*{Bewijs}
\begin{proof}
Rechtstreeks bewijs.\\
\[
v+x = w+x
\]
Tel bij beide leden het tegengestelde element van $x$ op.
\[
(v+x)+x' = (w+x)+x'
\]
Associativiteit.
\[
v + (x+x') = w+(x+x')
\]
Tegengesteld element.
\[
v + 0 = w+0
\]
Neutraal element
\[
v = w
\]
We gebruiken telkens eigenschappen van een commutatieve groep: de optelling\footnote{Zie Definitie 3.2 p 88}.
\end{proof}

\subsection{Lemma 3.8 p 93}
Zij $(\mathbb{R},V,+)$ een vectorruimte, $v\in V$ en $\lambda \in \mathbb{R}$.
\subsubsection*{Te Bewijzen}
\begin{enumerate}
\item
\[
0v = \vec{0} = \lambda\vec{0}
\]
\item
\[
(-1)v = -v 1(-v)
\]
\item
\[
(-\lambda)v = -(\lambda v ) = \lambda(-v)
\]
\end{enumerate}
\subsubsection*{Bewijs}
\begin{proof}
Bewijs door gefoefel.\\
De volgende redeneringen zullen initieel zeer artificieel aanvoelen maar als je deze kan reproduceren zal je veel makkelijk vanzelfsprekende dingen kunnen bewijzen.
\begin{enumerate}
\item 
\[
0v = (0+0)v = 0v + 0v
\]
De eerste gelijkheid geldt omwille van de eigenschap van het neutraal element van de optelling in $\mathbb{R}$. De tweede geldt omwille van distributiviteit-2\footnote{Zie Definitie 3.3 p 89}.
\[
0v = 0v+0v \Rightarrow 0v = \vec{0}
\]
De bovenstaande beweging volgt uit Lemma 3.7 op pagina 93.\\\\
Het tweede deel van dit bewijs is analoog.
\[
\lambda\vec{0} = \lambda(\vec{0}+\vec{0}) = \lambda\vec{0} + \lambda\vec{0} \Rightarrow \lambda\vec{0} = \vec{0}
\]
De eerste gelijkheid geldt opnieuw omwille van de eigenschap van het neurtraal element.\footnote{Zie Definitie 3.2 p 88} De tweede geldt omwille van distributiviteit-1\footnote{Zie Definitie 3.3 p 89}. De implicatie volgt opnieuw uit Lemma 3.7 op pagina 93.

\item
De eerste gelijkheid vergt enig gefoefel om te bewijzen.
We beginnen met iets triviaal.
\[0 = 0\]
Zie het eerste deel van dit bewijs.
\[0v = 0\]
Tegengesteld element in $\mathbb{R}$.
\[(-1+1)v = 0\]
Distributiviteit-2\footnote{Zie Definitie 3.3 p 89}.
\[(-1)v + v = -v + v\]
$v+x=w+x \Rightarrow v=w$\footnote{Zie Lemma 3.7 p 93}.
\[ (-1)v = -v\]
De tweede vergelijking daarentegen is een axioma van de vectorruimte: Co\"efficie\"ent 1\footnote{Zie Definitie 3.3 p 89}.

\item Dit is meer een bewijs dat wiskundigen van gefoefel houden!\\
Opnieuw beginnen we met iets triviaal.
\[0=0\]
Zie het eerste deel van dit bewijs.
\[0v = 0\]
Tegengesteld element in $\mathbb{R}$.
\[(-\lambda+\lambda)v = 0\]
Distributiviteit-2\footnote{Zie Definitie 3.3 p 89}.
\[(-\lambda)v + \lambda v = -(\lambda v) + \lambda v\]
$v+x=w+x \Rightarrow v=w$\footnote{Zie Lemma 3.7 p 93}.
\[(-\lambda)v = -(\lambda v)\]
Het tweede deel is echt niet beter.\\
Triviaal:
\[\vec{0} = \vec{0}\]
Zie het eerste deel van dit bewijs.
\[\vec{0} = \lambda \vec{0}\]
Tegengesteld element in de commutatieve groep $(V,+)$\footnote{Zie Definitie 3.2 p 88}.
\[\vec{0} = \lambda (-v+v)\]
Distributiviteit-1\footnote{Zie Definitie 3.3 p 89}.
\[-(\lambda v) + \lambda v = \lambda(-v)+\lambda v\]
$v+x=w+x \Rightarrow v=w$\footnote{Zie Lemma 3.7 p 93}.
\[-(\lambda v) = \lambda(-v)\]
\end{enumerate}
\end{proof}

\subsection{Stelling 3.11 p 94}
Zij $(\mathbb{R},V,+)$ een vectorruimte. $U \neq \emptyset$
\subsubsection*{Te Bewijzen}
\begin{center}
$U$ is een deelruimte van $V$
\end{center}
\[
\Leftrightarrow
\] 
\begin{enumerate}
\item $\forall x,y\in U: x+y\in U$.
\item $\forall x\in U, r\in \mathbb{R}: rx \in U$
\end{enumerate}
\[
\Leftrightarrow
\]
\[
\forall x,y\in U, r,s\in \mathbb{R}: rx+sy\in U
\]
\subsubsection*{Bewijs}
\begin{proof}
We bewijzen eerst de equivalentie van de eerste bewering met de tweede.\\
\emph{$\Rightarrow$}\\
Als $U$ een deelruimte is van $V$ dan is $U$ een vectorruimte\footnote{Zie Definitie 3.10 p 94}. Dan is $U$ niet leeg. Bovendien zijn $rx$ en $sy$ elementen van $U$ en $rx+sy$ dus ook.\\\\
\emph{$\Leftarrow$}\\
$U$ is niet leeg, dus $U$ bevat minstens \'e\'en element, noem het $u$. Uit de tweede voorwaarde geldt dan ook dat $-u \in U$. Uit de eerste voorwaarde geldt dan dat $u-u = \vec{0} \in U$. Voor elk element uit $U$ zit het tegengestelde ervan dus ook in $U$. Elke axioma uit definitie 3.2 en 3.3 zijn nu automatisch voldaan voor de elementen in $U$ omdat ze voldaan zijn in $V$.
\end{proof}

\subsection{Propositie 3.14 p 96}
\subsubsection*{Te Bewijzen}
De doorsnede van een aantal deelruimten van een vectorruimte $(\mathbb{R},V,+)$ is opnieuw een deelruimte van $V$
\subsubsection*{Bewijs}
\begin{proof}
Bewijs door inductie.\\
\emph{Stap 1: (basis)}\\
We bewijzen dat de bewering geldt voor precies twee deelruimten.
Noem $U$ en $W$ twee deelruimten van $V$. We weten nu dat stelling 3.11 op pagina 94 geldt voor $U$ en voor $W$. Om te bewijzen dat $U\cap W$ een deelruimte is van $V$ bewijzen we dat diezelfde stelling geldt voor $U\cap W$.
\[
\forall x,y\in U\cap W, r,s\in \mathbb{R}: rx+sy\in U\cap W
\]
<TODO meerverduidelijking.>
\emph{Stap 2: (inductie stap)}\\
We bewijzen nu dat als de bewerking geldt voor een bepaalde $k$, de bewering dan ook geldt voor $k+1$.
Stel dat $U_1,U_2,...,U_k,U_{k+1}$ deelruimten zijn van $V$. $\bigoplus_{i=1}^k U_i$ is een deelruimte van $V$ vanwege de inductiehypothese. $(\bigoplus_{i=1}^k U_i) \cap U_{k+1}$ is nu een deelruimte vanwege de basis stap.
\end{proof}

\subsection{Propositie 3.22 p 99}
Zij $(\mathbb{R},V,+)$. Zij $U_i$ deelruimten van $V$.
\subsubsection*{Te Bewijzen}
\begin{enumerate}
\item
\[
W = U_1 \oplus U_2
\]
\[\Leftrightarrow\]
\begin{enumerate}
\item
\[
W = U_1 + U_2
\]
\item
\[
U_1\cap U_2 = \{0\}
\]
\end{enumerate}
\item
\[
W = \bigoplus_{i}^kU_i
\]
\[\Leftrightarrow\]
\begin{enumerate}
\item
\[
W = \sum_i^k U_i
\]
\item
\[
\forall i \in \{1,2,...,k\}: U_i \cap (U_1+...+U_{i-1}+U_{i+1}+...+U_k)=\{0\}
\]
\end{enumerate}
\end{enumerate}
\subsubsection*{Bewijs}
\begin{proof}
\begin{enumerate}7
\item
\emph{$\Rightarrow$}\\
Stel dat $W = U_1 \oplus U_2$. Er bestaan dan voor elke $w\in W$ twee vectoren $u_1\in U_1$ en $u_2 \in U_2$. Dit betekent dat $W = U_1+U_2$. We bewijzen nu dat $U_1\cap U_2 = \{0\}$. Stel dat $v \neq 0 \in U_1\cap U_2$, dan kunnen we $v$ schrijven als $v+\vec{0}=\vec{0}+v$. Dit zou betekenen dat $W$ geen directe som meer is. $\vec{0}$ moet dus wel het enige element zijn in $U_1\cap U_2$.\\\\
\emph{$\Leftarrow$}\\
Stel dat $U_1\cap U_2 = \{\vec{0}\}$, dan tonen we nu aan dat $W = U_1+U_2$ een directe som is. Noem $w$ een vector in $W$. $w$ kan dan geschreven worden als volgt.
\[
w = u_1+u_2=u_1'+u_2'
\]
In deze uitdrukking zijn $u_1,u_1'$ vectoren in $U_1$ en $u_2,u_2'$ vectoren in $U_2$. Hieruit volgt dat $u_1-u_1'=u_2-u_2 \in U_1\cap U_2 = \{\vec{0}\}$. Dit klopt omdat $u_1-u_1' \in U_1$ en $u_2-u_2' \in U_2$ en $u_1-u_1'=u_2-u_2$. Bijgevolg geldt $u_1 = u_1'$ en $u_2=u_2'$. Dit houdt in dat elke $w \in W$ slechts op $1$ manier geschreven kan worden als de som van $u_1\in U_1$ en $u_2\in U_2$.
\item
Bewijs door inductie.\\
\emph{Stap 1: (basis)}\\
De bewering geldt voor $k=2$. Dit is bewezen in het eerste deel van dit bewijs.\\\\
\emph{Stap 2: (inductie stap)}\\
We gaan ervan uit dat de bewering geldt voor een bepaalde $k$, en bewijzen dat dat de bewering ook geldt voor $k+1$.
\[
W = (\bigoplus_i^k U_i) \oplus U_{k+1}
\]
Het eerste deel geldt omwille van de inductiehypothese, het tweede deel geldt omwille van de basis stap. <TODO meer uitleg hier>
\end{enumerate}
\end{proof}

\subsection{Propositie 3.26 p 101}
Gegeven een verzameling lineair onafhankelijke vectoren $D= \{v_1,v_2,...,v_n\}$.
\subsubsection*{Te Bewijzen}
\[
\sum_{i=1}^n\lambda_iv_i=0 \Leftrightarrow \lambda_1 = \lambda_2 = ... = \lambda_n = 0
\]
\subsubsection*{Bewijs}
\begin{proof}
\emph{$\Rightarrow$}\\
Bewijs uit het ongerijmde:\\
De volgende bewering zou equivalent moeten zijn met een contradictie.
\[
\sum_{i=1}^n\lambda_iv_i=0 \wedge \exists \lambda_i \neq 0
\]
Nu is het makkelijk te zien dat voor minstens \'e\'en $v$ geldt dat $v$ geschreven kan worden als een lineaire combinatie van de andere.
\[
v_k = -\frac{1}{y}\sum_{i\neq k}\lambda_iv_i
\]
De bovenstaande bewering houdt dan in dat de verzameling lineair afhankelijk is en dat is in contradictie met het gegeven.
\\\\
\emph{$\Leftarrow$}\\
Dit is evident waar\footnote{Zie Lemma 3.8 p 93 puntje 1.}.
\[
\sum_{i=1}^n0v_i=0
\]
\end{proof}

\subsection{Stelling 3.32 p 104}
Zij $(\mathbb{R},V,+)$ een vectorruimte en $A = \{x_1,x_2,...,x_m\}$ een deelverzameling van $m$ vectoren uit $V$.
\subsubsection*{Te Bewijzen}
\begin{enumerate}
\item
Als $A$ voortbrengend is voor $V$, dan is elke deelverzameling van $V$ met meer dan $m$ elementen lineair afhankelijk.
\item
Als $V$ vrij is, dan is elke deelverzameling van $V$ met minder dan $m$ vectoren niet voortbrengend voor $V$.
\end{enumerate}
\subsubsection*{Bewijs}
\begin{proof}
Ingewikkeld bewijs.\\
\begin{enumerate}
\item
Neem een willekeurige deelverzameling $B = \{y_1,...,Y_n\}$ van $V$ met $m > n$.\\
Doordat $A$ voortbrengend is voor $V$ kan elke vector van $B$ geschreven worden als een lineaire combinatie van de vectoren van $A$. Bijgevolg bestaan er co\"efficienten $a_{ij}\in \mathbb{R}$ zodat het volgende stelsel geldt.
\[
\left\lbrace
\begin{array}{c c}
y_1 = a_{11}x_1 + \cdots + a_{m1}x_m\\
y_2 = a_{12}x_1 + \cdots + a_{m2}x_m\\
\vdots\\
y_n = a_{1n}x_1 + \cdots + a_{mn}x_m\\
\end{array}
\right.
\]
We onderzoeken nu of de vectoren van $B$ al dan niet lineair afhankelijk zijn. Voor zekere co\"effici\"enten $c_i\in \mathbb{R}$ geldt het volgende met $y_i$ niet allemaal nul als $B$ niet vrij is.
\[
c_1y_1 + c_2y_2 + ... + c_ny_n = 0
\]
\[
\Leftrightarrow
c_1(a_{11}x_1 + \cdots + a_{m1}x_m) + c_2(a_{12}x_1 + \cdots + a_{m2}x_m) + ... + c_n(a_{1n}x_1 + \cdots + a_{mn}x_m) = 0
\]
\[
\Leftrightarrow
(a_{11}c_1+a_{12}x_2+...+a_{1n}c_n)x_1 + ... + (a_{m1}c_1+a_{m2}x_2+...+a_{mn}c_n)x_m
\]
Dit geldt zeker als het volgende stelsel geldt.
\[
\left\{
\begin{array}{c c}
a_{11}c_1+a_{12}x_2+...+a_{1n}c_n = 0\\
a_{21}c_1+a_{22}x_2+...+a_{2n}c_n = 0\\
\vdots\\
a_{m1}c_1+a_{m2}x_2+...+a_{mn}c_n = 0\\
\end{array}
\right.
\]
Dit is een homogeen stelsel met $m$ vergelijkingen in $n$ onbekenden. Bovendien hebben we gesteld dat $m<n$. Dit houdt in dat er minstens één vrije variabele zal zijn en het stelsel dus minstens één oplossing heeft verschillend van $\vec{0}$\footnote{Zie stelling 1.36 p 38}.
De elementen in $B$ zijn dus lineair afhankelijk.
\item
Neem opnieuw een willekeurige deelverzameling $B = \{y_1,...,y_n\}$ van $V$ maar deze keer met $n < m$. We zullen dit bewijzen uit het ongerijmde door ervan uit te gaan dat er een $B$ bestaat die wel voortbrengend is, en dan tot een contradictie te komen.
Omdat $B$ voortbrengend is geldt dat elk element uit $A$ geschreven kan worden als een lineaire combinatie van de elementen in $B$.
\[
\forall x \in A: \exists b_i \in \mathbb{R}: x = \sum_ib_iy_i
\]
Omdat $A$ vrij is geldt voor elke set $a_i$.
\[
\sum_ia_ix_i = 0 \Rightarrow \forall i: a_i = 0
\]
<TODO EN VERDER?>

\end{enumerate}
\end{proof}

\subsection{Gevolg 3.33 p 105}
Zij $A$ een deelverzameling van de vectorruimte $(\mathbb{R},V,+)$ met $m$ elementen.
\subsubsection*{Te Bewijzen}
Als $A$ voortbrengend is, dan bevat elke vrij deelverzameling van $V$ hoogstens $m$ elementen.
\subsubsection*{Bewijs}
\begin{proof}
We weten dat elke deelverzameling $B$ van $V$ met meer dan $m$ elementen niet meer vrij is. $B$ heeft dus hoogstends $m$ elementen.
\end{proof}

\subsection{Gevolg 3.34 p 105}
Zij $(\mathbb{R},V,+)$ een vectorruimte met een basis van $n$ vectoren.
\subsubsection*{Te Bewijzen}
Elke andere basis van $V$ heeft ook $n$ vectoren.
\subsubsection*{Bewijs}
\begin{proof}
Een basis is vrij en voortbrengend.
Volgens het lemma van Steinitz\footnote{Zie Stelling 3.32 p 104} is elke andere deelverzameling van $V$ met meer dan $n$ vectoren niet meer vrij en elke andere deelverzameling van $V$ met minder dan $n$ vectoren niet meer voortbrengend. Elke basis van $V$ heeft dus $n$ vectoren.
\end{proof}

\subsection{Stelling 3.37 p 107}
Zij $(\mathbb{R},V,+)$ een vectorruimte met dimensie $n$.
\subsubsection*{Te Bewijzen}
\begin{enumerate}
\item Elke vrije verzameling van $V$ kan uitgebreid worden tot een basis van $V$.
\item Elke eindige voortbrengende verzameling van $V$ kan uitgedund worden tot een basis van $V$.
\end{enumerate}
\subsubsection*{Bewijs}
\begin{proof}
\begin{enumerate}
\item
We kiezen een willekeurige vrije deelverzameling $D$ van $V$ met $k$ elementen. Nu geldt $k\le n$\footnote{Zie Gevolg 3.33 p 105}. Ofwel is $D$ voortbrengend, en dan moet $D$ niet uitgebreid worden. Ofwel bestaat er een vector $v\in V$ die niet in $D$ zit die geen lineaire combinatie is van vectoren uit $D$ want $D$ is niet voortbrengend. $D \cup \{v\}$ is vrij want $v$ is geen lineaire combinatie van vectoren in $D$. Dit proces kunnen we herhalen tot de resulterende deelverzameling een basis is.
\item
We kiezen een willekeurige voortbrengende deelverzameling $S$ van $D$. Te bewijzen is nu dat er een deelverzameling van $S$ bestaat die een basis is van $V$. We schappen eerst alle nulvectoren uit $S$. $S$ is dan nog steeds voortbrengend. We overlopen nu in volgorde de vectoren in $S$. We schappen elke vector die lineair afhankelijk is van de vorige vectoren. De overblijvende verzameling $B$ is een basis van $V$.\\
\emph{$B$ is voortbrengend:}\\
Elke vector in $S$ is een lineaire combinatie van $B$ en $S$ is voortbrengend. Bijgevolg is $B$ ook voortbrengend.\\
\emph{$B$ is vrij:}\\
Elke vector in $B$ is lineair onafhankelijk van zijn 'voorgangers'. Er bestaat dus geen niet-triviale lineaire combinatie van de elementen in $B$.
\end{enumerate}
\end{proof}

\subsection{Eigenschap 3.40 p 108}
Zij $V$ een $n$-dimensionale vectorruimte.
\subsubsection*{Te Bewijzen}
\begin{enumerate}
\item $n$ lineair onafhankelijke vectoren in $V$ vormen een basis van $V$.
\item $n$ voortbrengende vectoren in $V$ vormen een basis van $V$.
\end{enumerate}
\subsubsection*{Bewijs}
\begin{proof}
We weten dat elke basis van $V$ $n$ vectoren bevat.\footnote{Zie Gevolg 3.34 p 105}
\begin{enumerate}
\item
Stel $D$ is de verzameling van $n$ lineair onafhankelijke vectoren. $D$ kan uitgebreid worden tot een basis van $V$ door geen enkele vector toe te voegen. $D$ is dus een basis van $V$.
\item
Stel $E$ is de verzameling van $n$ voortbrengende vectoren. $D$ kan uitgedund worden tot een basis door geen enkele vector te verwijderen. $D$ is dus een basis van $V$.
\end{enumerate}
\end{proof}

\subsection{Stelling 3.41 p 109}
Zij $(\mathbb{R},V,+)$ een $n$-dimensionale vectorruimte. Zij $B$ een verzameling van $n$ vectoren uit $V$.
\subsubsection*{Te Bewijzen}
\begin{center}
$B$ is een basis van $V$.\\$\Leftrightarrow$\\
$B$ is een vrij deel van $V$.\\$\Leftrightarrow$\\
$B$ is een voortbrengend deel van $V$.
\end{center}
\subsubsection*{Bewijs}
\begin{proof}
We bewijzen niet elke implicatie, maar enkel de voorwaartse implicaties, en de implicatie van de laatste bewering naar de eerste.
\begin{itemize}
\item \emph{$B$ is een basis van $V \Rightarrow B$ is een vrij deel van $V$.}\\
Dit volgt rechtstreeks uit de definitie van een basis\footnote{Zie Definitie 3.31 p 104}.
\item \emph{$B$ is een vrij deel van $V \Rightarrow B$ is een voortbrengend deel van $V$}\\
$B$ kan uitgebreid worden tot een basis van $V$ door toevoeging van geen enkele vector\footnote{Zie Stelling 3.37 p 107}. $B$ is bijgevolg een basis van $V$, en dus voortbrengend volgens de definitie van een basis.
\item \emph{$B$ is een voortbrengend deel van $V \Rightarrow B$ is een basis van $V$.}\\
$B$ kan uitgedund worden tot een basis van $V$ door het verwijderen van geen enkele vector. $B$ is bijgevolg een basis van $V$.
\end{itemize}
\end{proof}

\subsection{Stelling 3.42 p 109}
Zij $(\mathbb{R},V,+)$ een vectorruimte en $\beta \subset V$.
\subsubsection*{Te Bewijzen}
\begin{center}
$\beta$ is een basis van $V$.\\$\Leftrightarrow$\\
$\beta$ is maximaal vrij.\\$\Leftrightarrow$\\
$\beta$ is minimaal voortbrengend.
\end{center}
\subsubsection*{Bewijs}
We bewijzen niet elke implicatie, maar enkel de voorwaartse implicaties, en de implicatie van de laatste bewering naar de eerste.
\begin{proof}
\item \emph{$\beta$ is een basis van $V \Rightarrow \beta$ is maximaal vrij.}\\
$\beta$ is voortbrengend voor $V$ dus elke deelverzameling van $V$ met meer dan $n$ vectoren is niet meer vrij. Dit betekent precies dat $\beta$ maximaal vrij is.
\item \emph{$\beta$ is maximaal vrij. $\Rightarrow \beta$ is minimaal voortbrengend.}\\
Omdat elke vrije verzameling kan uitgebreid worden tot een (voortbrengende) basis van $V$, kan dit ook voor $\beta$\footnote{Zie Stelling 3.37 p 107}. Als we echter $\beta$ nog uitbreiden zal $\beta$ niet meer vrij zijn, want $\beta$ is maximaal vrij. Bijgevolg is $\beta$ zelf al een basis voor $V$. Volgens het lemma van Steinitz\footnote{Zie Stelling 3.32 p 104} is elke verzameling kleiner dan $\beta$ niet meer voortbrengend. $\beta$ is dus minimaal voortbrengend.
\item \emph{$\beta$ is minimaal voortbrengend. $\Rightarrow \beta$ is een basis van $V$.}\\ $\beta$ is een voortbrengende verzameling van $V$, en kan dus uitgedund worden tot een basis van $V$. Omdat $\beta$ minimaal voortbrengend is, zou de verwijdering van slechts $1$ er al voor zorgen dat $\beta$ niet meer voortbrengend zou zijn. $\beta$ is bijgevolg al een basis van $V$.
\end{proof}

\subsection{Stelling 3.43 p 110}
Zij $(\mathbb{R},V,+)$ een eindig dimensionale vectorruimte en $U$ een deelruimte van $V$.
\subsubsection*{Te Bewijzen}
\begin{enumerate}
\item $U$ is eindig voortgebracht en $dimU \le dimV$
\item $dimU=dimV \Leftrightarrow U = V$
\end{enumerate}
\subsubsection*{Bewijs}
\begin{proof}
Dit bewijs wordt graag gevraagd en staat niet volledig in het boek.
\begin{enumerate}
\item
Als $U=\{\vec{0}\}$ geldt, dan wordt $U$ eindig voortgebracht door de basis: $\emptyset$\footnote{Niet $\{\vec{0}\}$! want $\vec{0}$ is lineair afhankelijk van zichzelf.}. $dimU = 0$ bijgevolg geldt zeker dat $dimU\le dimV$ want dimensies zijn nooit negatief.\\
Als $U \neq \{\vec{0}\}$, dan kiezen we een vector $u_1 \in U$. We kunnen nu telkens \'e\'en lineair onafhankelijke vector $u_i$ toevoegen tot we een maximaal vrij deel $\beta$ van $U$ bekomen. Dit maximaal vrij deel is een basis van $U$ en bevat bijgevolg $dimU$ vectoren. $\beta$ brengt $U$ voort en het aantal vectoren in $\beta$ is eindig omdat de vectoren uit $\beta$ ook lineair onafhankelijk moeten zijn in $V$. $U$ wordt dus minimaal voortgebracht door $\beta$ en $dimU \le dimV$.
\item
\begin{itemize}
\item $\Rightarrow$\\
In het vorige deel van dit bewijs hebben we bewezen dat $U$ eindig voortgebracht wordt door een basis $\beta$ met $dimU$ elementen. Wanneer we nu weten dat $dimU=dimW$, dan volgt daaruit dat de basis $\beta$ van $U$ dus ook een basis is van $W$ omdat $U$ een deelruimte is van $V$. Omdat $U$ en $V$ dezelfde basis hebben, geldt $U = V$.
\item $\Leftarrow$\\
Omdat $U$ gelijk is aan $V$ heeft $U$ dezelfde basis als $V$. In twee dezelfde verzamelingen zitten evenveel elementen, dus $dimU=dimV$.
\end{itemize}
\end{enumerate}
\end{proof}

\subsection{Stelling 3.45 p 111}
Zij $(\mathbb{R},V,+)$ een vectorruimte en zij $\beta = \{v_1,v_2,...,v_n\}$ een basis van $V$.
\subsubsection*{Te Bewijzen}
Elke vector kan op een unieke wijze als een lineaire combinatie van de basisvectoren uitgedrukt worden. Er bestaat dus een bijectieve afbeelding $co_{\beta}$ die $v$ afbeeldt op het stel co\"effici\"enten dat correspondeert met $v$ ten opzichte van de basis $\beta$.
\[
co_{\beta}: V \rightarrow \mathbb{R}^n
 : \mapsto co_{\beta}(v)\]
\subsubsection*{Bewijs}
\begin{proof}
Bewijs uit het ongerijmde.\\
Elke vector $v\in V$ kan geschreven worden als een lineaire combinatie van de basisvectoren.
\[
v = a_1v_1 + a_2v_2 + ... + a_nv_n
\]
Stel nu dat er nog zo een lineaire combinatie bestaat, zodat $(a_1,a_2,...,a_n)$ geen uniek stel co\"effici\"enten is, dan kan $v$ ook nog op een andere manier geschreven worden. Noem dit ander stel co\"effici\"enten $(b_1,b_2,...,b_n)$.
\[
v = a_1v_1 + a_2v_2 + ... + a_nv_n = b_1v_1 + b_2v_2 + ... + b_nv_n
\]
Hieruit volgt het volgende.
\[ 
(a_1-b_1)v_1 + (a_2-b_2)v_2 + ... + (a_n-b_n)v_n= 0
\]
Dit is een lineaire combinatie van de basisvectoren van $V$. Omdat de basis vrij is moeten alle co\"efficienten $(a_i-b_i)$ nul zijn. Dit is in contradictie met de aanname dat het stel co\"effici\"enten niet uniek is. Het stel co\"effici\"enten is dus wel uniek.
\end{proof}

\subsection{Stelling 3.49 p 114}
\subsubsection*{Te Bewijzen}
Als de vectorruimte V eindigdimensionaal is, dan geldt voor willekeurige deelruimten $U$ en $W$ van $V$ het volgende.
\[
dim(U+W) + dim(U\cap W) = dim(U) + dim(W)
\]
\subsubsection*{Bewijs}
We willen een verband vinden tussen de dimensies van al deze verzamelingen ($(U+W)$, $U\cap W$, $U$ en $W$). Om dit te doen beginnen we met een basis van de kleinste verzameling ($U \cap W$). Daarna breiden we deze basis uit tot een basis van $U$, tot een basis van $W$ en tot een basis van $(U + W)$. De dimensie van een vectorruimte is gelijk aan het aantal elementen in de basis ervan.\footnote{Definitie 3.35 p 106}\\\\
Zij $dim(U) = r$, $dim(W)=s$ en $dim(U\cap W) = t$.
\begin{proof}
Ingewikkeld bewijs.\\
$U$ en $W$ zijn beide een deelruimte van $V$, dus $(U \cap W)$ is ook een deelruimte van $V$ \footnote{Propositie 3.14 p 96}. Omdat $(U \cap W)$ een deelruimte is van $V$, zal $t \le r$ en $t \le s$. We nemen een basis van $(U\cap W)$ en noemen deze $\beta = \{v_1,...,v_n\}$.Om $\beta$ uit te breiden tot een basis $\beta_U$ van $U$ moet we $r-t$ vectoren toe voegen. Om $\beta$ uit te breiden tot een basis $\beta_W$ van $W$ moeten we $s-t$ vectoren toe.\\
De basisvectoren van $U$ zijn dus $\{v_i,...,v_t,u_{t+1},...,u_r\}$. Bovendien zijn de basisvectoren van $W$, $\{v_i,...,v_t,w_{t+1},...,w_k\}$.
We willen bewijzen dat de basis $\beta_U \cup \beta_W = \{v_1,...,v_t,u_{t+1},...,u_{r},w_{t+1},...,w_{s}\}$ een basis is van $U+W$.
Een basis van een vectorruimte is vrij en voortbrengend. We bewijzen deze eigenschappen appart.\\
\textbf{Vrij}\\
Neem een willekeurige lineaire combinatie van de basisvectoren van $(U+W)$.
\[
0 = \sum_{i=1}^tx_iv_i + \sum_{j=t+1}^ry_ju_j + \sum_{k=t+1}^sz_kw_k
\]
Om te bewijzen dat de $\beta_U \cup \beta_W$ vrij is, moeten we bewijzen dat alle $v_i,y_j,z_k$ nul zijn.\\
De vector $\sum_{k=t+1}^sz_kw_k \in W$ zit in $W$ omdat alle $w_k \in W$. Bovendien kan deze vector geschreven worden als volgt.
\[
\sum_{k=t+1}^sz_kw_k = -\sum_{i=1}^tx_iv_i - \sum_{j=t+1}^ry_ju_j
\]
Deze vector zit bijgevolg in $U$ en dus ook in $U\cap W$ want ze valt te schrijven als een lineaire combinatie van de basisvectoren van $U$ ($\beta_U$).
Omdat $\sum_{k=t+1}^sz_kw_k \in (U\cap W)$ is de volgende bewering waar.
\[
\exists \lambda_i \in \mathbb{R} \sum_{k=t+1}^sz_kw_k = \sum_{i=1}^t\lambda_iv_i
\]
\[
\exists \lambda_i \in \mathbb{R} \sum_{k=t+1}^sz_kw_k - \sum_{i=1}^t\lambda_iv_i = 0 
\]
Het linkerlid van de bovenstaande vergelijking is een lineaire combinatie van de basisvectoren van $W$. Van deze basisvectoren weten we dat ze lineair onafhankelijk zijn, dus moeten alle $z_k, \lambda_i$ nul zijn. We weten nu dus al dat alle $z_k$ in de originele vergelijking nul zijn.\\
Dezelfde redenering kunnen we toepassen op de vector $\sum_{j=t+1}^ry_ju_j \in U$. Deze vector kan geschreven worden als volgt.
\[
\sum_{j=t+1}^ry_ju_j= -\sum_{i=1}^tx_iv_i - \sum_{k=t+1}^sz_kw_k
\]
Deze vector zit dus in $W$ en bijgevolg ook in $(U\cap W)$ want ze valt te schrijven als een lineaire combinatie van de basisvectoren $W$ ($\beta_W$). Omdat $\sum_{j=t+1}^ry_ju_j \in (U\cap W)$ is de volgende bewering waar.
\[
\exists \lambda_i \in \mathbb{R} \sum_{j=t+1}^ry_ju_j = \sum_{i=1}^t\lambda_iv_i
\]
\[
\exists \lambda_i \in \mathbb{R} \sum_{j=t+1}^ry_ju_j - \sum_{i=1}^t\lambda_iv_i = 0 
\]
Het linkerlid van de bovenstaande vergelijking is een lineaire combinatie van de basisvectoren van $W$. We weten dat deze lineair onafhankelijk zijn, dus moeten alle $y_j,  \lambda_i$ ook nul zijn.\\
In de eerste vergelijking weten we nu al dat alle $z_k,y_j$ nul zijn. Nu blijft er dus nog het volgende over.
\[
0 = \sum_{i=1}^tx_iv_i + 0 + 0
\]
Het rechterlid van deze vergelijking is een lineaire combinatie van de basisvectoren van $U\cap W$. Van deze vectoren weten we dat ze lineair onafhankelijk zijn, dus alle $x_i$ moeten nul zijn.
Nu hebben we bewezen dat $\beta_U\cup \beta_W$ een basis is van $U+W$\\\\
\textbf{Voortbrengend}\\
Om te bewijzen dat een basis voortbrengend is voor een vectorruimte nemen we een willekeurig element uit te vectorruimte en tonen we aan dat het een lineaire combinatie is van de basis.
Neem een willekeurig element $x \in (U + W)$. We tonen de volgende bewering aan.
\[
\exists x_i,y_j,z_k \in \mathbb{R}: x = \sum_{i=1}^tx_iv_i + \sum_{j=t+1}^ry_ju_j + \sum_{k=t+1}^sz_kw_k
\]
We weten ook dat $\exists u\in U, w\in W: x = u+w$. De volgende bewering geldt dus zeker.\footnote{Definitie 3.19 p 98}
\[
\exists x_a,x_b,y_j,z_k \in \mathbb{R}  u+w = \sum_{a=1}^tx_av_a + \sum_{j=t+1}^ry_ju_j + \sum_{b=1}^tx_bv_b + \sum_{k=t+1}^sz_kw_k
\]
Kiezen we nu de $x_a,x_b$ zodat de volgende bewering geldt.
\[
\sum_{i=1}^tx_iv_i = \sum_{a=1}^tx_av_a + \sum_{b=1}^tx_bv_b 
\]
Nu is aangetoond dat $\beta_U \cup \beta_W$ voortbrengend is.
\\\\ 
We weten nu dat $\beta_U \cup \beta_W$ een basis is van $U+W$. De basis van $\beta_U \cup \beta_W$ bevat precies $(r-t)+(s-t)+t = r+s-t$ basisvectoren. Als we nu terug kijken naar de benaming van de dimensies van $U$, $W$ en $U\cap W$ zien we het volgende.
\[
dim(U+W) r+s-t = dim(U) + dim(W) + dim(U \cap W)
\]
\end{proof}

\subsection{Stelling 3.52 p 115}
Zij $(\mathbb{R},V,+)$ een eindig dimensionale vectorruimte. Zij $U_1,...,U_k$ deelruimten van $V$ zodat $V=\bigoplus_{i=1}^kU_i$. Zij $\beta_i$ de basissen van deze deelruimten.
\subsubsection*{Te Bewijzen}
$\bigcup_{i=1}^k\beta_i$ is een basis van $V$ en de volgende bewering geldt dus ook.
\[
dimV = \sum_{i=1}^kdimU_i
\]
\subsubsection*{Bewijs}
\begin{proof}
We moeten bewijzen dat $\bigcup_{i=1}^k\beta_i$ vrij en voortbrengend is.
\begin{itemize}
\item \emph{Vrij}\\
We moeten bewijzen dat als een lineaire combinatie van de basisvectoren $\beta_i$ gelijk is aan nul, de co\"effici\"enten van deze combinatie dan nul zijn. Zij $\beta_i = {v_1^{(i)},v_2^{(i)},...,v_{m_i}^{(i)}}$, dan ziet deze combinatie er als volgt uit.
\[
\vec{0} = \sum_{i=1}^k\sum_{j=1}^{m_i}\lambda_j^{(i)}v_j^{(i)}
\]
Omdat $V$ de directe soms is van $U_1,...,U_k$ is de nulvector $\vec{0}$ slechts op \'e\'en manier te schrijven als de som van elementen in $U_1,...,U_k$. De nulvector is altijd te schrijven als $\vec{0} = \vec{0} + \vec{0} + ... + \vec{0}$ waarbij elke $\vec{0}$ komt uit een andere $U_i$. Dit betekent het volgende.
\[
\forall i: \sum_{j=1}^{m_i}\lambda_j^{(i)}v_j^{(i)} = 0
\]
Dit zijn lineaire combinaties van de basisvectoren dus alle $\lambda_j^{(i)}$ zijn nul.
\item \emph{Voortbrengend}\\
Per definitie kan elke vector in de somruimte van deelruimten geschreven worden als som van een vector uit elke deelruimte\footnote{Zie Definitie 3.19 p 98}.
Elk van de vectoren uit de deelruimte kan geschreven worden als een lineaire combinatie van de basisvectoren ervan. Elke vector in de somruimte $V$ van de deelruimten $U_1,...,U_k$ kan dus geschreven worden als de som van lineaire combinatie van de basisvectoren van elke deelruimte. Deze som is ook een lineaire combinatie van de unie van de basissen van de deelruimten. De unie van de basissen is dus voortbrengend voor $V$.
\end{itemize}
Omdat de doorsnede van elke twee $U_i$ gelijk is aan $\{\vec{0}\}$ is de doorsnede van elke twee $\beta_i$ leeg. Bijgevolg geldt dat $\#(\bigcup_{i=1}^k\beta_i) = \sum_{i=1}^k\#(\beta_i)$. Hieruit volgt direct het te bewijzen.
\[
dimV = \sum_{i=1}^kdimU_i
\]
\end{proof}

\subsection{Stelling 3.56 p 116}
Zij $(\mathbb{R},V,+)$ een eindigdimensionale vectorruimte met basis.
\subsubsection*{Te bewijzen}
Elke deelruimte van $V$ heeft een complementaire deelruimte.
\subsubsection*{Bewijs}
\begin{proof}
Zij $U$ een deelruimte van $V$ met basis $\beta_U = \{u_1,u_2,...,u_n)$. $U$ kan uitgebreid worden tot een basis van $V$ met vectoren $w_1,w_2,...,w_k$. Deze vectoren $w_i$ spannen dan $W$ op zodat de volgende bewering geldt.
\[
U \oplus W = V
\]
\begin{itemize}
\item $V = U + W$\\
Alle vectoren uit $V$ moeten geschreven kunnen worden als de som van een vector uit $U$ en een vector uit $W$. Alle vectoren in $U$ respectievelijk $W$ kunnen geschreven worden als de lineaire combinatie van de basisvectoren van $U$, respectievelijk $W$. Hieruit volgt dat alle vectoren uit $V$ geschreven kunnen worden als de sum van lineaire combinaties van basissen van deelruimten. Deze som is precies de lineaire combinatie die we gebruiken om de vector te vormen door een lineaire combinatie van de basisvectoren in $V$.

\item $U\cap W = \{\vec{0}\}$\\
De vectoren uit de basis van $U$ zijn lineair onafhankelijk van de vectoren uit de basis van $W$. In de doorsnede van deze deelruimten zit dus enkel de nulvector.
\end{itemize}
\end{proof}

\subsection{Stelling 3.60 p 119}
Zij $A \in \mathbb{R}^{m\times n}$ en zijn $U$ de rijgereduceerde matrixvorm van $A$.
\subsubsection*{Te Bewijzen}
\begin{enumerate}
\item 
\[
N(A) = N(U)
\]
\item
\[
R(A) = R(U)
\]
\item
\[
dimN(A) + dimR(A) = n
\]
\end{enumerate}
\subsubsection*{Bewijs}
\begin{proof}
Bewijs in woorden.
\begin{enumerate}
\item We weten uit hoofdstuk 1 dat de oplossingsverzameling van het stelsel $A\cdot X = \vec{0}$ gelijk is aan die van $U\cdot X = \vec{0}$. Dit betekent precies het volgende.
\[
N(A) = N(U)
\]
TODO VERWIJZEN NAAR EEN BEWIJS
\item De matrix $U$ ontstaat uit $A$ door elementaire rijoperaties. Elementaire rijoperaties veranderen de rijruimte van een matrix niet. 
\[
R(A) = R(U)
\]
TODO BEWIJS DIT
\item
$dimR(U)$ is precies gelijk aan het aantal niet-nulrijen in $U$.
$dimN(U)$ is gelijk aan het aantal vrije variabelen van het stelsel $U\cdot X = \vec{0}$. Het aantal niet-vrije variabelen (niet-nulrijen) plus het aantal vrije variabelen is gelijk aan het totaal aantal variabelen.
\end{enumerate}
\end{proof}

\subsection{Stelling 3.61 p 120}
Zij $A \in \mathbb{m \times n}$ en $B \in \mathbb{n \times o}$ zodat $A\times B$ bepaald is.
\subsubsection*{Te Bewijzen}
\begin{enumerate}
\item
\[
N(B) \subset N(AB)
\]
\item
\[
C(AB) \subset C(A)
\]
\item
\[ 
R(AB)\subset R(B)
\]
\end{enumerate}
\subsubsection*{Bewijs}
\begin{proof}
\begin{enumerate}
\item
Stel dat $X\in N(B)$, dan geldt dat $BX=0$. We tonen nu aan dat ook $(AB)X=0$ geldt.
\[(AB)X=0\]
\[A(BX)=0\]
\[A0=0\]
\[0=0\]
\item
$C(AB)$ is de verzameling van alle lineaire combinaties van kolommen van $AB$. De kolommen van $AB$ zijn van de vorm $Ab_i$ met $b_i$ kolommen van $B$. $Ab_i$ is een lineaire combinatie van de kolommen van $A$. Voor elke vector $v \in C(AB)$ geldt dus $v\in C(A)$. Met andere woorden geldt het volgende.
\[C(AB) \subset C(A)\]
\item
Door middel van enig gefoefel kunnen we dit gemakkelijk bewijzen.
De rijruimte van een matrix is gelijk aan de kolomruimte van de getransponeerde matrix.
\[
R(AB) = C((AB)^T)
\]
Nu passen we een eigenschap van getransponeerde matrices toe\footnote{Zie Eigenschappen p 32}
\[
(AB)^T = B^TA^T
\]
Door het vorige deel van dit bewijs weten we nu het volgende over kolomruimtes.
\[
C(B^TA^T) \subset C(B^T)
\]
Nu vormen we dit opnieuw om naar een kolomruimte om het bewijs te vervolledigen.
\[
C(B^T) = R(B)
\]
\end{enumerate}
\end{proof}

\section{Oefeningen 3.6}
\subsection{oef 1}
\subsubsection*{b)}
distributiviteit-2 geldt niet.
\[
(\lambda_1 + \lambda_2)v = \lambda_1v = \lambda_2v
\]
en niet
\[
(\lambda_1 + \lambda_2)v = \lambda_1v+\lambda_2v
\]

\subsubsection*{c)}
optelling is niet commutatief.
\[
(x_1,y_1) + (x_2,y_2) = (x_1+2x_2,y_1+2y_2)
\]
\[ \neq \]
\[
(x_2,y_2) + (x_1,y_1) = (x_2+2x_1,y_2+2y_1)
\]

\subsection{oef 2}
\subsubsection*{a)}
Deze verzameling vormt de unie van de drie vlakken rond de assen. Dit is geen deelruimte want de optelling is niet intern.\\
\underline{Tegenvoorbeeld:}\\
\[
(1,0,0) + (0,1,1) = (1,1,1) \not \in W_1
\]
\subsubsection*{b)}
$W_2$ is geen deelruimte van $\mathbb{R}^{3}$.\\
\underline{Tegenvoorbeeld:}\\
$x = (3, 4, 5) \in W_2$ en $y = (2, 2, \sqrt{8}) \in W_2$ maar $x + y = (5, 6, 5 + \sqrt{8}) \not \in W_2$

\subsubsection*{e) }
waar\\
*) $0 \in W_5$ \\
*) $A,B \in W_5 \longmapsto A+B \in W_5$ \\
$ \sum\limits_{i=1,j=1}^a (A+B)_{ij} = \sum\limits_{i=1,j=1}^a A_{ij} + \sum\limits_{i=1,j=1}^a B_{ij} = 0+0 = 0 $ \\
*) $ A \in W_5, \lambda \in R \longmapsto \lambda A \in W_5$ \\
$ \sum\limits_{i=1,j=1}^a (\lambda A)_{ij} = \lambda \sum\limits_{i=1,j=1}^a A_{ij} = \lambda 0 = 0$


\subsubsection*{f)}
$W_6$ is geen deelruimte van $R^{3\times 3}$ want de volgende eigenschap geldt niet: (zie p 94)
\[
\forall x,y\in W_6,\;\forall r,s\in\mathbb{R}:\; r\cdot x+s\cdot y\in U
\]
Tegenvoorbeeld:
stel $x=y$, $r=1$ en $s=-1$.\\
Concreet:
\[
x = I_3
\]

\subsubsection*{g)}
$W_7$ is een deelruimte van $\mathbb{R}^{3x3}$.\\
\begin{proof} 

1) $W_7$ bevat het nulelement. De nulmatrix is immers ook een symmetrische matrix. \\
2) $ Symm(A1) + Symm(A2) = A3 $
	and $A3 = \mathbb{R}^{3x3}$ \\
3) $ \lambda \cdot Symm(A) = A2 $
	and $ A2 = \mathbb{R}^{3x3}$

Er is voldaan aan de drie eigenschappen.

\end{proof}


\subsubsection*{i)}
$W_9$ is geen deelruimte van $R^{3\times 3}$. De optelling is namelijk niet intern.
\[
(0,1,0) + (1,0,0) = (1,1,0) \not \in W_9
\]

\subsubsection*{j)}
$W_{10}$ is geen deelruimte van $R\rightarrow R$ want het neutraal element van $R\rightarrow R$  zit niet in $W_{10}$.
\subsubsection*{l)}
Neem $f, g \in W_{12}$ en $\lambda, \mu \in \mathbb{R}$ willekeurig.\\
Omdat $f$ en $g$ integreerbaar zijn, is $\lambda f + \mu g$ integreerbaar.
\begin{align*}
  \int^1_0 (\lambda f + \mu g)(x)dx &= \int^1_0(\lambda f(x) + \mu g(x))dx\\
  &= \int^1_0 \lambda f(x)dx + \int^1_0 \mu g(x)dx\\
  &= \lambda \int^1_0 f(x)dx + \mu \int^1_0 g(x)dx = \lambda \cdot 0 + \mu \cdot 0 = 0
\end{align*}
$W_{12}$ is dus een deelruimte van $\mathbb{R} \rightarrow \mathbb{R}$.



\subsection*{oef 3}
\subsubsection*{Optelling}
\underline{Associativiteit:}\\
Stel $r_1$, $r_2$, $r_3$ willekeurige rijen met differentievergelijking $x_{n + 2} = x_{n + 1} + x_n$.\\
Dan geldt
\begin{align*}
    (r_1 + r_2) + r_3 &= (a_1 + b_1) + c_1 , (a_2 + b_2) + c_2 , ... , (a_n + b_n)+ c_n\\
    &= a_1 + b_1 + c_1, a_2 + b_2 + c_2, ... , a_n + b_n + c_n\\
    &= a_1 + (b_1 + c_1), a_2 + (b_2 + c_2), ..., a_n + (b_n + c_n)
\end{align*}
\underline{Neutraal element:}\\
We nemen als neutraal element de nulrij 0, met $x_1 = 0, x_2 = 0$ . 
Door de differentievergelijking is ieder volgend element ook nul.\\
Hierdoor geldt dan voor een willekeurige rij r
\begin{align*}
  r + 0 &= a_1 + 0, a_2 + 0, ..., a_n + 0\\
  &= a_1, a_2, ..., a_n\\
  &= r\\
  &= 0 + a_1, 0 + a_2, ..., 0 + a_n\\
  &= 0 + r
\end{align*}
\underline{Tegengesteld element:}\\
Als er een rij $r$ bestaat met $x_1 = a_1$, $x_2 = a_2$, dan kiezen we als tegengesteld element de rij $r'$ met $x_1 = -a_1$ en $x_2 = -a_2$.\\
Hierdoor geldt dan
\begin{align*}
    r + r' &= a_1 - a_1, a_2 - a_2, ...,a_n - a_n\\
    &= 0, 0, ..., 0\\
    &= -a_1 + a_1, -a_2 + a_2, ..., -a_n + a_n\\
    &= r' + r
\end{align*}
\underline{Commutativiteit:}\\
Stel $r_1$, $r_2$ willekeurige rijen met differentievergelijking $x_{n + 2} = x_{n + 1} + x_n$.\\
Dan geldt
\begin{align*}
    r_1 + r_2 &= a_1 + b_1, a_2 + b_2, ..., a_n + b_n\\
    &= b_1 + a_1, b_2 + a_2, ..., b_n + a_n\\
    &= r_2 + r_1
\end{align*}
\subsubsection*{Scalaire vermenigvuldiging}
\underline{Distributiviteit-1:}\\
Stel $r_1$, $r_2$ willekeurige rijen met differentievergelijking $x_{n + 2} = x_{n + 1} + x_n$, en een willekeurige $\lambda \in \mathbb{R}$.
\begin{align*}
    \lambda \cdot(r_1 + r_2) &= \lambda (a_1 + b_1), \lambda (a_2 + b_2), ..., \lambda (a_n + b_n)\\
    &= \lambda a_1 + \lambda b_1, \lambda a_2 + \lambda b_2, ..., \lambda a_n + \lambda b_n\\
    &= \lambda \cdot r_1 + \lambda \cdot r_2
\end{align*}
\underline{Distributiviteit-2:}\\
Stel $r$ een willekeurige rij met differentievergelijking $x_{n + 2} = x_{n + 1} + x_n$, en een willekeurige $\lambda_1 , \lambda_2 \in \mathbb{R}$.
\begin{align*}
    (\lambda_1 + \lambda_2) \cdot r &= (\lambda_1 + \lambda_2) a_1, (\lambda_1 + \lambda_2) a_2, ..., (\lambda_1 + \lambda_2) a_n\\
    &= \lambda_1 a_1 + \lambda_2 a_1, \lambda_1 a_2 + \lambda_2 a_2, ..., \lambda_1 a_n + \lambda_2 a_n\\
    &= \lambda_1 \cdot r + \lambda_2 \cdot r
\end{align*}
\underline{Gemengde associativiteit:}\\
Stel $r$ een willekeurige rij met differentievergelijking $x_{n + 2} = x_{n + 1} + x_n$, en een willekeurige $\lambda_1 , \lambda_2 \in \mathbb{R}$.
\begin{align*}
    \lambda_1 \cdot (\lambda_2 \cdot r) &= \lambda_1 \cdot (\lambda_2 a_1), \lambda_1 \cdot (\lambda_2 a_2), ..., \lambda_1 \cdot (\lambda_2 a_n)\\
    &= (\lambda_1 \cdot \lambda_2) a_1, (\lambda_1 \cdot \lambda_2) a_2, ..., (\lambda_1 \cdot \lambda_2) a_n\\
    &= (\lambda_1 \cdot \lambda_2) \cdot r
\end{align*}
\underline{Co\"effici\"ent 1:}\\
Stel $r$ een willekeurige rij met differentievergelijking $x_{n + 2} = x_{n + 1} + x_n$.
\begin{align*}
     1 \cdot r &= 1 \cdot a_1, 1 \cdot a_2, ..., 1 \cdot a_n\\
     &= a_1, a_2, ..., a_n\\
     &= r
\end{align*}

\subsection*{oef 4}
Welke oef uit de definitie van een vectorruimte zijn voldaan? \\
1. De optelling is inwendig en overal bepaald, ja \\
2. De optelling is associatief,	ja \\
3. Er is een neutr element, ja \\
4. Elk element heeft een tegeng element, ja \\
5. De opt is comm, nee \\

1. Distr-1, \\
2. Distr-2, ja \\
3. gemeng asso, ja\\
4. nee

\subsection{oef 5}
Ja, $W$ is een deelruimte van $R[X]_{\le n}$ als $n\ge 1$.
\subsubsection*{Te bewijzen}
\[
\forall w_1,w_2 \in W,\forall \lambda_1,\lambda_1 \in \mathbb{R}: \lambda_1w_1+\lambda_2w_2 \in W
\]
\subsubsection*{Bewijs}
\begin{proof}
Voor elke $w_1,w_2 \in W, \lambda_1,\lambda_1 \in \mathbb{R}$ geldt dat $ \lambda_1w_1+\lambda_2w_2 \in W$ want $w_1$ en $w_2$ zijn ofwel nul ofwel hebben ze graad $n$. Elke lineaire combinatie zal dus ofwel nul zijn ofwel graad $n$ hebben.
\end{proof}


\subsection{oef 6}
\subsubsection*{Gegeven}
$U$ en $W$ zijn deelruimten van een vectorruimte $(\mathbb{R},V,+)$.
\subsubsection*{Te Bewijzen}
\[
U \cup W \text{ is een deelruimte van }V \Leftrightarrow U \subset W \vee W \subset U
\]
\subsubsection*{Bewijs}
\begin{proof} Samengesteld bewijs.
\\Deel 1: $(\Rightarrow)$
\\ Te bewijzen:
\[
U \cup W \text{ is een deelruimte van }V \Rightarrow U \subset W \vee W \subset U
\]
Bewijs uit het ongerijmde.
\\Stel dat $\neg(U \subset W \wedge W \subset U)$.
\\Dit is equivalent met $U \not\subset W \wedge W \not\subset U$.
Vanuit de definitie van deelverzameling betekent deze bewering het volgende.
\[
(\exists w': w' \in W \wedge w' \not\in U) \wedge (\exists u': u' \in U \wedge u' \not\in W) 
\]
We moeten nu tot een contradictie komen met ``$U\cup W \text{ is een deelruimte van }V$''.
$U\cup W \text{ is een deelruimte van }V$ betekent vanuit de definitie het volgende.
\[
\forall w, u \in ĉ,\; \forall \lambda_1 , \lambda_2 \in \mathbb{R}: \lambda_1\cdot u + \lambda_2\cdot w \in U\cup W
\]
Aangezien deze bewering geldt voor elke $w,i \in U\cup W$, geldt ze ook voor $w'$ en $u'$.
We weten nu het volgende.
\[
\forall \lambda_1 , \lambda_2 \in \mathbb{R}: \lambda_1\cdot u' + \lambda_2\cdot w' \in U\cup W
\]
met $w' \in W \wedge w' \not\in U$ en $u' \in U \wedge u' \not\in W$.\\
Als dit geldt voor elke $\lambda_1$ en $\lambda_2$, geldt het ook voor $\lambda_1= \lambda_2 = 1$ en geldt dus het volgende.
\[
u' + w' \in U \cup W
\]
We weten dat dit niet klopt, want stel als $u' + w' \in U \cup W$ en $u' \in U$, dan $w' \in U$. Contradictie.
\\Deel 2: $(\Leftarrow)$
\\ Te bewijzen:
\[
U \cup W \text{ is een deelruimte van }V \Leftarrow U \subset W \vee W \subset U
\]
Direct bewijs.\\
Stel $U \subset W$. (Het andere geval is volledig analoog)\\
Als $U \subset W$, dan is $U\cup W = W$. Van $W$ is gegeven dat het een deelruimte is van $W$. Hiermee is bewezen dat $U\cup W$ een deelruimte is van $V$.6
\end{proof}

\subsection*{oef 7}
Om te zien of een vector $d$ tot een deelruimte behoort opgespannen door vectoren $v_1$ en $v_2$ en $v_3$ moeten we zien of er een lineaire combinatie bestaat zodat  $$a\cdot v_1 + b\cdot v_2 + c\cdot v_3 = d$$
Dus:
$$a(2,-1,3,2) + b(-1,1,1,-3) + c(1,1,9,-5) \overset{?}{=} (3,-1,0,-1)$$
We gieten dit in een matrix:
$$
\begin{pmatrix}
2 & -1 & 1 &3\\
-1 & 1 & 1 & -1\\
3 & 1 &9 & 0\\
2 & -3 &-5& -1
\end{pmatrix}
$$
Door rijreductie verkrijgen we volgende matrix:
$$
\begin{pmatrix}
1&0&2&0\\
0&1&3&0\\
0&0&0&1\\
0&0&0&0
\end{pmatrix}
$$
Dit is een ongeldige matrix en dus bestaat er geen lineaire combinatie zodat de vector $d$ gevormd wordt. De vector behoort dus niet tot de deelruimte.

\subsection{Oefening 8}
We willen $p(X)$ opschrijven als lineaire combinatie van $p_1(X), p_2(X), p_3(X)$, dus $p(X) = \lambda_1 p_1(X) + \lambda_2 p_2(X) + \lambda_2 p_3(X)$.
Hiervoor lossen we het volgende stelsel op:
\[
\left\{
\begin{array}{l l l l l}
  -1 &= &\lambda_1 &+ 2 \lambda_2 &+ 3 \lambda_3\\
  -3 &= &2 \lambda_1 &+ 5 \lambda_2 &+ 8 \lambda_3\\
  3 &= &\lambda_1 &&- 2 \lambda_3
\end{array}
\right.
\]
Dit vullen we in in een matrix, die we hierna oplossen m.b.v. rijreductie.
\[
\begin{pmatrix}[ccc|c]
  1 & 2 & 3 & -1\\
  2 & 5 & 8 & -3\\
  1 & 0 & -2 & 3
\end{pmatrix}
\rightarrow
\begin{pmatrix}[ccc|c]
  1 & 0 & 0 & -1\\
  0 & 1 & 0 & 3\\
  0 & 0 & 1 & -2
\end{pmatrix}
\]
We resulteren dus dat $p(X) = - p_1(X) + 3 p_2(X) - 2 p_3(X)$.


\subsection{Oefening 9}
$$f(x)+g(x)-h(x)+0\cdot exp(x) = 0$$
$$1 - 1 + 0 = 0$$
Dit is een lineaire combinatie waarbij niet alle co\"effi\"enten nul zijn en toch de nulvector als oplossing geeft. Hierdoor is
$\{f,g,h,exp\}$ geen lineair onafhankelijke deelruimte.
\subsection*{oef 12}
Moest dit waar zijn dan mag er uit de verzameling $\{ e_1-e_2,e_2-e_3,\dots ,e_{n-1}-e_n,e_n-e_1\}$ geen enkel element bestaan dat een combinatie is van de andere elementen.
$$
\text{We zien nu voor}\ 1 \leq i \leq n:
$$
$$ 
(e_1-e_2)+(e_2-e_3)+\dots +(e_{i-1}-e_i)+(e_{i+1}-e_{i+2})+\dots + (e_n - e_1)
$$
$$
= (\not e_1-\not e_2+\not e_2-\not e_3+\dots +\not e_{i-1}-e_i+e_{i+1}-\not e_{i+2}+\dots + \not e_n - \not e_1)
$$
$$
= -e_i + e_{i+1}
$$
Dus voor een willkeurige vector:
$$
e_i - e_{i+1} = -\left((e_1-e_2)+(e_2-e_3)+\dots +(e_{i-1}-e_i)+(e_{i+1}-e_{i+2})+\dots + (e_n - e_1)\right)
$$
kunnen we dus telkens een combinatie vinden uit de andere vectoren, hierdoor is het geen vrij deel. 
\subsection{Oefening 13}
Hiervoor kunnen we aantonen dat $\{1+X,1+X^2,X+X^2\}$ minimaal voortbrengend is, hiervoor laten we zien dat elke vector uit  $(\mathbb{R},\mathbb{R}[X]_{\leq 2},+)$ een lineaire combinatie is van de basisvectoren:
$$aX^2 + bX + c = \lambda_{1} (1+X) + \lambda_{2} (1+X^2) + \lambda_{3} (X+X^2)$$
Als we deze vergelijking uitwerking uitwerken krijgen we:
$$a = \lambda_{1} + \lambda_2$$
$$b = \lambda_1 + \lambda_3$$
$$c = \lambda_1 + \lambda_2$$
Dit is een stelsel met exact 1 oplossing. Hierme tonen we aan dat het stelsel voortbrengend is en minimaal voortbrengend. Moesten we nog extra vergelijkingen er aan toevoegen zouden we redundantie invoeren of het stelsel onoplosbaar maken.
\\
\\
De co\"ordinaten van de vector $4 -3X + X^2$ kunnen we berekenen ze in een stelsel te gieten:
$$
\begin{pmatrix}
1&1&0&4\\
1&0&1&-3\\
0&1&1&1
\end{pmatrix}
$$
Via rijoperaties verkrijgen we dan:
$$
\begin{pmatrix}
1&0&0&0\\
0&1&0&4\\
0&0&1&-3
\end{pmatrix}
$$
Dit komt overeen met de co\"ordinaten $(0,4,-3)$.
\\
\\
Het co\"ordinatenstel $(2,-3,1)$ komt dan weer overeen met:
$$
2\cdot (1+X) -3 \cdot (1+X^2)+ 1\cdot (X+X^2)= -1 +3X-2X^2
$$

\subsection{Oefening 14}

\subsubsection*{a)}
Beschouwen we eerst de verzameling met alleen het eerste element van de voorgestelde basis. We voegen nu stapsgewijs de daaropvolgende elementen toe, en proberen voor elk toegevoegd element dit element te schrijven als een lineaire combinatie van de reeds toegevoegden. Indien dit lukt maakt het de verzameling lineair afhankelijk en voegen we het niet toe. Indien het geen lineaire combinatie is kunnen we het toevoegen aan onze nieuwe verzameling zonder de vrijheid ervan in gevaar te brengen.\\

Het toevoegen van $(1,2,0)$ is triviaal. Geen veelvoud van $(1,2,3)$ kunnen we gelijk stellen hieraan. Het mag dus bij de verzameling. De volgende elementen zullen we meer systematisch aanpakken.\\

Bij het toevoegen van $(1,1,1)$ proberen we dit te schijven als een lineaire combinatie van de voorgaande als volgt:\\
\[
a * (1,2,3) + b * (1,2,0) = (1,1,1)
\]

Dit is equivalent met het stelsel
\[
\left\{
\begin{array}{l}
a + b = 1\\
2*a + 2*b = 1\\
3*a = 1
\end{array} \right.
\]

wat resulteert in het strijdig (in de eerste twee regels, maar ook indien men het verder probeert uit te werken) stelsel

\[
\left\{
\begin{array}{l}
a + b = 1\\
a + b = \frac{1}{2}\\
a = \frac{1}{3}
\end{array} \right.
\]

$(1,1,1)$ is dus geen lineaire combinatie van de eerste twee, en mogen we dus aan onze vrije verzameling toevoegen, deze blijft vrij. Passen we dit stramien toe op de volgende vector, namelijk $(1,1,0)$, vinden we dat deze een lineaire combinatie is, namelijk
\[
-\frac{1}{3} * (1,2,3) + \frac{1}{3} * (1,2,0) + (1,1,1) = (1,1,0)
\]
Dit kunnen we makkelijk met een stelsel bekomen. We zien dus dat dit een lineaire combinatie is, en voegen het niet toe aan de verzameling. Deze is dus nog steeds $\{(1,2,3), (1,2,0), (1,1,1)\}$.

De laatste vector schrijven we nog even met een stelsel op voor de duidelijkheid. Indien het stelsel

\[
\left\{
\begin{array}{l}
a + b + c = 4\\
2*a + 2*b + c = 5\\
3*a + c = 6
\end{array} \right.
\]

klopt, dan is de vector $(4,5,6)$ een lineaire combinatie van onze vrije verzameling.

We kunnen dit oplossen als matrix die we rijreduceren:

\[
\left[
\begin{array}{c c c | c}
1 & 1 & 1 & 4\\
2 & 2 & 1 & 5\\
3 & 0 & 1 & 6
\end{array}
\right]
\]

\[R2 \mapsto -R2 + 2*R1 \]
\[R3 \mapsto -R3 + 2*R1 \]
(Dit zijn niet echt volledig correcte overgangen op elementair niveau, maar eerder een samentrekking)

\[
\left[
\begin{array}{c c c | c}
1 & 1 & 1 & 4\\
0 & 0 & 1 & 3\\
0 & 3 & 2 & 6
\end{array}
\right]
\]

\[R2 \leftrightarrow R3\]

\[
\left[
\begin{array}{c c c | c}
1 & 1 & 1 & 4\\
0 & 3 & 2 & 6\\
0 & 0 & 1 & 3
\end{array}
\right]
\]

\[R1 \mapsto R1 - R3 \]
\[R2 \mapsto R2 - 2*R3 \]

\[
\left[
\begin{array}{c c c | c}
1 & 1 & 0 & 1\\
0 & 3 & 0 & 0\\
0 & 0 & 1 & 3
\end{array}
\right]
\]

\[R2 \mapsto \frac{R2}{3}\]

\[
\left[
\begin{array}{c c c | c}
1 & 1 & 0 & 1\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 3
\end{array}
\right]
\]

\[R1 \mapsto R1 - R2\]

\[
\left[
\begin{array}{c c c | c}
1 & 0 & 0 & 1\\
0 & 1 & 0 & 0\\
0 & 0 & 1 & 3
\end{array}
\right]
\]

We besluiten dus dat $(4,5,6)$ een lineaire combinatie is uit onze verzameling, namelijk\\

\[
(1,2,3) + 3 * (1,1,1) = (4,5,6)
\]

Deze mag dus niet bij in de verzameling.\\

De uitgedunde verzameling is dus $\{(1,2,3), (1,2,0), (1,1,1)\}$.\\

Dit is de originele verzameling waar stapsgewijs de lineaire combinaties uitgehaald zijn, en deze is dus vrij.

\subsubsection*{b)}

We kunnen voor de verzameling via de vorige oefening bepalen dat deze vrij is, dat laten we even buiten beschouwing.\\

We willen deze verzameling voortbrengend maken. Dit betekent dat elk element van $\mathbb{R}^{2x2}$ moet kunnen geschreven worden als een combinatie van de elementen uit de verzameling.\\

Beschouwen we de standaardbasis $\{\bigl(
\begin{smallmatrix}
1&0\\ 0&0
\end{smallmatrix}
\bigr)$,
$\bigl(
\begin{smallmatrix}
0&1\\ 0&0
\end{smallmatrix}
\bigr)$,
$\bigl(
\begin{smallmatrix}
0&0\\ 1&0
\end{smallmatrix}
\bigr)$,
$\bigl(
\begin{smallmatrix}
0&0\\ 0&1
\end{smallmatrix}
\bigr)$\}, dan kunnen we stellen dat elk van deze elementen te vormen moet zijn uit onze voorgestelde basis, als lineaire combinatie. Indien dit voor alle elementen van de standaardbasis geldt is de verzameling voortbrengend, immers, we kunnen de elementen van de standaardbasis vormen en hier lineaire combinaties van maken om alle elementen uit $\mathbb{R}^{2x2}$ te schrijven.\\

Indien er een element van de standaardbasis is dat niet als lineaire combinatie geschreven kan worden mogen we dit toevoegen, het is immers niet lineair afhankelijk, de verzameling blijft dus vrij, en de verzameling brengt nu ook dat element van de standaardbasis voort.

Voor $\bigl(
\begin{smallmatrix}
1&0\\ 0&0
\end{smallmatrix}
\bigr)$ kijken we of we deze kunnen vormen als lineaire combinatie via de matrix

\[
\left[
\begin{array}{c c c | c}
1 & 2 & 0 & 1\\
-1 & 1 & -3 & 0\\
2 & -1 & 5 & 0\\
3 & 4 & 4 & 0
\end{array}
\right]
\]

\[R2 \mapsto R2 + R1 \]
\[R3 \mapsto R3 - 2*R1 \]
\[R4 \mapsto R4 - 3*R1 \]

\[
\left[
\begin{array}{c c c | c}
1 & 2 & 0 & 1\\
0 & 3 & -3 & 1\\
0 & -5 & 5 & -2\\
0 & -2 & 4 & -2
\end{array}
\right]
\]

\[R3 \mapsto 3*R3 + 5*R2 \]
\[R4 \mapsto 3*R4 + 3*R2 \]

\[
\left[
\begin{array}{c c c | c}
1 & 2 & 0 & 1\\
0 & 3 & -3 & 1\\
0 & 0 & 0 & -1\\
0 & 0 & -6 & -4
\end{array}
\right]
\]

Het stelsel is strijdig, dus kunnen we beslissen dat $\bigl(
\begin{smallmatrix}
1&0\\ 0&0
\end{smallmatrix}
\bigr)$ geen lineaire combinatie is van onze verzameling. Deze mag er dus bij zonder dat de vrijheid van de verzameling verdwijnt.\\

Nu kunnen we al beslissen dat onze basis volledig is volgens Gevolg 3.34. De standaardbasis heeft namelijk 4 elementen en deze verzameling ook. Aangezien de verzameling tevens vrij is mogen we beslissen dat de verzameling $\{\bigl(
\begin{smallmatrix}
1&-1\\ 2&3
\end{smallmatrix}
\bigr)$,
$\bigl(
\begin{smallmatrix}
2&1\\ -1&4
\end{smallmatrix}
\bigr)$,
$\bigl(
\begin{smallmatrix}
0&-3\\ 5&4
\end{smallmatrix}
\bigr)$,
$\bigl(
\begin{smallmatrix}
1&0\\ 0&0
\end{smallmatrix}
\bigr)$\} een basis is van $\mathbb{R}^{2x2}$.\\

Indien $\bigl(
\begin{smallmatrix}
1&0\\ 0&0
\end{smallmatrix}
\bigr)$ wel een lineaire combinatie was zouden we deze niet toegevoegd hebben, en de andere elementen van de standaardbasis ge\"evalueerd hebben. Er moet immers volgens eerder aangehaald gevolg nog precies een element toegevoegd worden aan onze verzameling om een basis te kunnen zijn.

\subsection{Oefening 16}

Standaard basis : $\beta1 = {e1 =(1,0,0,0), e2 =(0,1,0,0), e3 = (0,0,1,0), e4 = (0,0,0,1) }$

tweede basis : $\beta2 = {f1 = (1,1,1,1), f2 =(0,1,1,1), f3 = (0,0,1,1), f4= (0,0,0,1) }$

volgens $\beta1  V = a1e1 + a2e2 + a3e3 + a4e4$
volgens $\beta2 V = \lambda1 \cdot f1 + \lambda2 \cdot f2 + \lambda3 \cdot f3 + \lambda4 \cdot f4 $ 

$=> (\lambda1, \lambda2, \lambda3, \lambda4) $

\subsection{oef 17}
\subsubsection*{a)}
$W_1$ vormt een vlak. We zoeken twee lineair onafhankelijke vectoren in dat vlak, die zijn dan een basis.
\[
\left\lbrace
\begin{pmatrix}
1\\-2\\1\\
\end{pmatrix}
,
\begin{pmatrix}
2\\-2\\0
\end{pmatrix}
\right\rbrace
\]

\subsubsection*{b)}
Voor de basis te kennen lossen we eerst volgend stelsel op want hieraan moet voldaan zijn:
$$
\begin{pmatrix}[c c c | c]
1 & 2&-1&0\\
2&1&1&0\\
\end{pmatrix}
$$
Hiervoor krijgen we de oplossing $x=-k$, $y= k$, $z=k$. Een oplossing is dus telkens van de vorm $(-k,k,k)$.\\
We krijgen dus als basis:
$$W_2 = \{(-\lambda, \lambda, \lambda)|\lambda \in \mathbb{R}\}$$
De dimensie is dus 1.
\subsection*{oef 19}
\subsubsection*{b)}
\[ A =
\begin{pmatrix}
  1 & 1 & 1\\
  1 & 1 & -1\\
  1 & -1 & 1\\
  1 & -1 & -1
\end{pmatrix}
\]
Na Gauss-eliminatie krijgen we de rij-gereduceeerde vorm
\[ U =
\begin{pmatrix}
  1 & 0 & 0\\
  0 & 1 & 0\\
  0 & 0 & 1\\
  0 & 0 & 0
\end{pmatrix}
\]
Hierdoor krijgen we de oplossingsverzameling $\{(0,0,0)\}$.\\
De basis van de \underline{nulruimte} is dus $\emptyset$.\\
De rijen $r_1, r_2, r_3$ zijn niet-nulrijen, de basis van de \underline{rijruimte} is dus $vct\{(1,1,1), (1,1,-1), (1,-1,1)\}$.\\
De kolommen $c_1, c_2, c_3$ zijn onafhankelijk en voortbrengend, de basis van de \underline{kolomruimte} is dus $vct\{(1,1,1,1), (1,1,-1,-1), (1,-1,1,-1)\}$.

\subsubsection*{c)}
\[
\begin{pmatrix}
0 & 1 & -1 &  -2 & 1 \\
1 & 1 & -1 & 3   & 1 \\
2 & 1 & -1 & 8   & 3 \\
0 & 0 & -2 & 2   & 1 \\
3 & 5 & -5 & 5   & 10\\
\end{pmatrix}
\longrightarrow
\begin{pmatrix}
1 & 0 & 0 & 5 & 0 \\
0 & 1 & 0 & -3& 0 \\
0 & 0 & 1 & -1& 0 \\
0 & 0 & 0 & 0 & 0 \\
0 & 0 & 0 & 0 & 0 \\
\end{pmatrix}
\]
De eerste drie rijen van deze gereduceerde matrix vormen een basis voor de rijruimte.
De eerste drie kolommen van de gereduceerde matrix vormen een basis voor de kolomruimte. 
De oplossing van het homogeen stelsel van de gereduceerde matrix vormt de nullruimte van de matrix.
De oplossingsverzameling is de volgende.
\[
\{(-5\lambda_1,3\lambda_1,\lambda_1,\lambda_1,\lambda_2)|\lambda_1,\lambda_2\in \mathbb{R}\}
\]
We kiezen hieruit twee onafhankelijke vectoren ($2=5-3$).
\[
\left\lbrace
\begin{pmatrix}
-5\\3\\1\\1\\0\\
\end{pmatrix}
,
\begin{pmatrix}
0\\0\\0\\0\\1\\
\end{pmatrix}
\right\rbrace
\]

\subsection{oef 23}
Ik ga ervan uit dat we een bewijs moeten geven van deze stelling. Het staat er namelijk nergens bij.\\
Zij $V$ een vectorruimte met $\beta$ een basis ervan. Zij $\beta_1,...,\beta_k$ de disjuncte unie ervan. Noteer $U_i=vct(\beta_i)$.
\subsubsection*{Te Bewijzen}
\[
V = U_1 \oplus U_2 \oplus ... \oplus U_k
\]
\subsubsection*{Bewijs}
\begin{proof}
We weten dat voor elke $\beta_i,\beta_j$ de vectoren lineair onafhankelijk zijn, want samen vormen ze een basis. We weten dus al dat $\forall U_i,U_j: U_i \cap U_j = \{0\}$.\\
Nu hoeven we enkel nog te bewijzen dat $\sum_i U_i=V$. Voor elke $u_i \in U_i$ geldt dat $u_i = \sum_k\lambda_k\beta_{ik}$, in woorden: "elke $u_i$ is een lineaire combinatie van de basisvectoren van $U_i$. $\sum_i U_i$ bevat alle mogelijke lineaire combinaties van alle mogelijke $u_i$. Deze combinaties kunnen geschreven worden als lineaire combinaties van de vectoren in $\beta$. Nu hebben we dus bewezen dat $\sum_i U_i=V$ en $\forall U_i,U_j: U_i \cap U_j = \{0\}$. Hieruit volgt dat $\bigoplus_iU_i=V$.
\end{proof}



\subsection{oef 25}
Toon aan:
$ U \bigoplus W = \mathbb{R}^{n x n}$

\begin{proof}
Wat zijn de voorwaarden die moeten voldoen?
1) $ U + W = \mathbb{R}^{n x n}$
2) $ U \cap W = {0}$

nakijken 1) :
Het is duidelijk dat de doorsnede van U en W enkel de nulmatrix is.

nakijken 2) : 
De som van 2 vierkante matrices met grootte n is opniew een vierkante matrix met afmeting n. $U + W = \mathbb{R}^{n x n}$

QED

\end{proof}

\subsection*{oef 26}
We kiezen $U = vct\{(0,1,0), (0,0,1)\}$.\\ Hierdoor is $(\mathbb{R}, \mathbb{R}^3, +) = U + W$ en $U \cap W = \{0\}$.\\
Dan is $v = v_U + v_W$ en $w = w_U + w_W$ met
\[
v_U = (0,-10,-8), 
v_W = (2,12,8), 
w_U = (0,4,4), 
w_W = (0,0,0)
\]

\subsection*{oef 27}
\subsubsection*{a)}
$$\lambda_1 v_1 = \lambda_2 v_2 = 0$$
$$\lambda_1(1,0,1,1,2,3,5,8,...) + \lambda_2(0,1,1,2,3,5,8,...)=(0,0,0,0,0,...)$$
We nemen nu de eerste component van $v_1$ en $v_2$:
$$\lambda_1 \cdot 1 + \lambda_2 \cdot 0 = 0$$
$$\Rightarrow \lambda_1 = 0$$

$$\lambda_1 \cdot 0 + \lambda_2 \cdot 1 = 0$$
$$\Rightarrow \lambda_2 = 0$$
\subsubsection*{b)}
We beweren dat $v_3 = v_1 + v_2$.\\
We bewijzen dat $(v_3)_n = (v_1 + v_2)_n$ \hspace{5pt} $\forall n \in \mathbb{N}$\\
Dit tonen we aan per inductie:\\
\underline{Basisstap:} $(v_1 + v_2)_0 = (v_3)_0 \rightarrow (1 + 0) = 1$\\
\hspace*{4.5em} $(v_1 + v_2)_1 = (v_3)_1 \rightarrow (0 + 1) = 1$\\
\underline{Inductiestap:} Neem $n \geq 2$ en veronderstel dat $(v_1 + v_2)_{n-1} = (v_3)_{n-1}$ en $(v_1 + v_2)_{n-2} = (v_3)_{n-2}$.\\
\[
(v_1 + v_2)_n \overset{v_1 + v_2 \in V}{=} (v_1 + v_2)_{n-1} + (v_1 + v_2)_{n-2} \overset{inductiehypothese}{=} (v_3)_{n-1} + (v_3)_{n-2} = (v_3)_n
\]
\subsubsection*{c)}
Een basis is vrij en voortbrengend. $\beta = \{v_1,v_2\}$ is vrij (zie a).
Nu valt nog te bewijzen: "$\beta$ is voortbrengend voor $V$."
\begin{proof}
Neem een willekeurige vector $v \in V$. We tonen aan dat $v$ te schrijven valt als een lineaire combinatie van $v_1$ en $v_2$.
\[
v=(x_1,x_2,x_3,...)
\]
Waarbij geldt $\forall n \ge 1, n \in \mathbb{N}: x_{n+2}=x_{n+1}+x_n$
\[
v = \lambda_1v_1 + \lambda_2v_2
\]
\[
v = (\lambda_1,\lambda_2,\lambda_1+\lambda_2,\lambda_1+2\lambda_2,...)
\]
Elk element in $v$ voldoet dus aan de volgende recursieve formule.
\[
v_{n+2} = v_{n+1}+v_n=\lambda_1v_{1_{n+1}}+\lambda_2v_{2_{n+1}} + \lambda_1v_{1_{n}}+\lambda_2v_{2_{n}};
\]
Dit is juist volgens de definitie van vectorsom en scalaire vermenigvuldiging.
\end{proof}

\subsubsection*{d)}
$v_3 = (1,1)$

\subsection{oef 28}
\subsubsection*{b)}
Zij $V = \{(1,0,...),(0,1,0,...),(0,0,1,0,...),...)\}$.\\
\textbf{Te Bewijzen}\\
$V$ is geen basis van $\mathbb{R}^\mathbb{N}$.\\
\textbf{Bewijs}
\begin{proof}
In 28 a hebben we bewezen dat $V$ een vrij deel is van $\mathbb{R}^\mathbb{N}$. Om te bewijzen dat $V$ geen basis is van $\mathbb{R}^\mathbb{N}$ moeten we dus aantonen dat $V$ niet voortbrengend is voor $\mathbb{R}^\mathbb{N}$.
TODO <wat betekent $\mathbb{R}^\mathbb{N}$?>
\end{proof}

\subsection{oef 30}

\begin{proof}

Eerst de optelling.
De optelling is inwendig en overal bepaald zoals uit $R_{0}^{+} x R_{0}^{+} \rightarrow R_{0}^{+} $ 
De optelling is associatief.
$ (x + y) + z = x + (y+z) $
$ xy + z = x + yz$
$ xyz = xyz $

Er is een neutraal element.
$x \cdot 1 = x $

GEEN Tegengesteld element.
Het is niet mogenlijk om een uniek tegengesteld element te vinden voor elk element dat gelijk is aan 0.

Commutatief!
$xy = yx$

Alle eigenschappen voor de optelling zijn niet voldaan, dus het is geen geldige definitie.

Bij $ \bigotimes $ geldt distr1 ook al niet.

\end{proof}

\subsection{Oefening 31}
\subsubsection*{a)}
Neen, dit is geen deelruimte; dit is zelfs geen vectorruimte. Een simpel tegenvoorbeeld:\\

$(1,0,1)$ is een element van de verzameling, alsook $(1,0,-1)$, dit is makkelijk na te gaan door invulling. Hun som daarentegen, $(2,0,0)$ voldoet niet aan het voorschrift.\\

Hierdoor is niet voldaan aan Stelling 3.11 en is $K$ bijgevolg geen deelruimte.

\subsubsection*{b)}

De dimensie van $\mathbb{R}^3$ is 3, dit komt triviaal voort uit de standaardbasis $\{(1,0,0),(0,1,0),(0,0,1)\}$.\\

De verzameling $\{(1,0,1),(0,1,1),(0,0,1)\}$ van elementen uit $K$ is lineair onafhankelijk, dit is triviaal te bewijzen met de stelsels

\[
\left\{
\begin{array}{l}
a = 0\\
0 = 1\\
a = 1
\end{array} \right.
\]

en

\[
\left\{
\begin{array}{l}
a = 0\\
b = 0\\
a + b = 1
\end{array} \right.
\]

die we met het uitdunningsalgoritme bekomen. Beide zijn strijdig, dus is de verzameling vrij. Roepen we weer Stelling 3.11 aan, weten we dat voor $\mathbb{R}^3$ een vrije verzameling met 3 elementen een basis is. Aangezien de verzameling een basis bevat van $\mathbb{R}^3$, wordt $\mathbb{R}^3$ ook voortgebracht door $K$ zelf.

\subsection{oef 32}
We berekenen alle $a$ waarvoor de vier gegeven basisvectoren lineair afhankelijk zijn.
\[
\begin{vmatrix}
4+a & 3 & 3 & 0\\
2 & a-1 & 5 & 10+a\\
0 & 0 & a+1 & 0\\
-2 & -1 & -5 & 0
\end{vmatrix}
= -(2-a)(10+a)(a+1)=0
\]
\[
\Leftrightarrow 
\left\lbrace
\begin{array}{c c}
a = 2 &\vee\\
a = -10 &\vee\\
a = -1\\
\end{array}
\right.
\]
Nu weten we dus dat als $a$ \textit{niet} \'e\'en van die waarden aanneemt, de doorsnede van $U$ en $W$, $\{\vec{0}\}$ zal zijn. Een basis van $\{\vec{0}\}$ is de lege verzameling en de dimensie ervan is $0$.
Tenslotte bepalen we nog voor de speciale gevallen van $a$ de dimensie en een basis.
\subsubsection*{$a = 2$}
\[
\left\lbrace
\begin{pmatrix}
6\\2\\0\\-2
\end{pmatrix}
,
\begin{pmatrix}
3\\1\\0\\-1
\end{pmatrix}
\right\rbrace
\left\lbrace
\begin{pmatrix}
3\\5\\3\\-5
\end{pmatrix}
,
\begin{pmatrix}
0\\12\\0\\0
\end{pmatrix}
\right\rbrace
\]
Als $a=2$ dan zien we dat de twee vectoren die $U$ opspannen lineair afhankelijk zijn. $U_2$ is dus \'e\'endimensionaal. Als we de eerste vector verwijderen zijn de overblijvende vectoren lineair afhankelijk. De dimensie van de somruimte is dus $3$. Bij gevolg is de dimensie van de doorsnede $0$ en de basis ervoor $\emptyset$.
\subsubsection*{$a=-10$}
\[
\left\lbrace
\begin{pmatrix}
5\\2\\0\\-2
\end{pmatrix}
,
\begin{pmatrix}
3\\-11\\0\\-1
\end{pmatrix}
\right\rbrace
\left\lbrace
\begin{pmatrix}
3\\5\\-5\\-5
\end{pmatrix}
,
\begin{pmatrix}
0\\0\\0\\0
\end{pmatrix}
\right\rbrace
\]
Hier is de dimensie van $W_a$ $1$. De als we de laatste vector verwijderen blijven er weer drie lineair onafhankelijke vectoren over. De dimensie vande doorsnede is weer $0$ en de basis daarvoor weer $\emptyset$.
\subsubsection*{$a=-1$}
\[
\left\lbrace
\begin{pmatrix}
3\\2\\0\\-2
\end{pmatrix}
,
\begin{pmatrix}
3\\-2\\0\\-1
\end{pmatrix}
\right\rbrace
\left\lbrace
\begin{pmatrix}
3\\5\\0\\-5
\end{pmatrix}
,
\begin{pmatrix}
0\\9\\0\\0
\end{pmatrix}
\right\rbrace
\]
We weten dat voor elke vector $u = \begin{pmatrix}
u_1\\u_2\\u_3\\u_4
\end{pmatrix} \in V\cap W$ geldt:
\[\exists \lambda_1,\lambda_2 :u = 
\lambda_1
\begin{pmatrix}
3\\2\\0\\-2
\end{pmatrix} + 
\lambda_2
\begin{pmatrix}
3\\-2\\0\\-1
\end{pmatrix}
\wedge
\exists \lambda_3,\lambda_4 :u = 
\lambda_3
\begin{pmatrix}
3\\5\\0\\-5
\end{pmatrix} + 
\lambda_4
\begin{pmatrix}
0\\9\\0\\0
\end{pmatrix}
\]
\[
\left\lbrace
\begin{array}{r l l}
u_1 &= 3\lambda_1+3\lambda_2 &= 3\lambda_3\\
u_2 &= 2\lambda_1-2\lambda_2 &= 5\lambda_3+9\lambda_4\\
u_3 &= 0\\
u_4 &= -2\lambda_1 -1\lambda_2 &= -5\lambda_3
\end{array}
\right.
\]
?? TODO <wat nu?!>

\section{Oefenzitting 5}
\subsection{oef 1}
\subsubsection*{1.1}
\underline{+} is de som van de functies\\
Neem $f,g,h \in \mathbb{R}^{\mathbb{R}}$ willekeurig.\\
Neem $x \in \mathbb{R}$ willekeurig dan is:
\begin{align*}
((f\underline{+}g)+h)(x) = (f\underline{+} g)(x) +h(x)\\
=(f(x)+g(x))+h(x)\\
=f(x)+(g(x)+h(x))\\
=f(x)+(g\underline{+}h)(x)\\
=(f\underline{+}(g\underline{+}h)(x))\\
\end{align*}
Dus:
\begin{align*}
(f\underline{+}g)\underline{+}h = f\underline{+}(g\underline{+}h)
\end{align*}
\subsubsection*{1.3}
Tegengesteld element:
\[
\forall v \in V:\;\exists v' \in V:\; v+v'=v'+v=0
\]
Stel $g'$ is het tegengesteld element van $g$.
Noteer het neutraal element als $\odot$.
\[
g' = (-1)\bullet g
\]
\begin{proof}
\[
g\textbf{+}g' = g\textbf{+} (-1)\bullet g
\]
We evalueren dit in een willekeurige $x \in R$:
\[ 
(g\textbf{+} (-1)\bullet g)(x) \overset{def\;1}{=} g(x) -g(x) = 0 = \odot
\]
Vanwege de commutativiteit geldt ook:
\[
g(x) -g(x) = -g(x) + g(x) = 0 = \odot
\]
\end{proof}
\subsubsection{1.4}
Stel $f:\mathbb{R} \rightarrow \mathbb{R}: x \mapsto f(x)$ en $g:\mathbb{R} \rightarrow \mathbb{R}: x \mapsto g(x)$, dan geldt voor iedere $x \in \mathbb{R}$ dat
\[ (\lambda \bullet (f \boldsymbol{+} g))(x) 
    = \lambda (f \boldsymbol{+} g)(x) 
    = \lambda (f(x) + g(x))
    = \lambda \cdot f(x) + \lambda \cdot g(x)
    = (\lambda \bullet f)(x) + (\lambda \bullet g)(x)
    = (\lambda \bullet f \boldsymbol{+} \lambda \bullet g)(x)\]
en dus $\lambda \bullet (f \boldsymbol{+} g) = \lambda \bullet f \boldsymbol{+} \lambda \bullet g $
\section{Bewijzen}
\subsection{Lemma 3.7}

$$v+x = w + x \Rightarrow v=w$$
Neem $v,w,x \in V$ en we nemen aan dat $v+x = w+x$\\
\begin{align*}
v = v + 0 \tag{neutraal element}\\
= v + (x - x) \tag{invers element}\\
=(v+x) -x \tag{communativiteit}\\
=(w+x) -x \tag{dit hebben we aangenomen}\\
= w +(x-x) \tag{communitativiteit}\\
= w+0 \tag{invers element}\\
=w \tag{neutraal element}
\end{align*}

\subsection{Lemma 3.8 punt 3}
\[(-\lambda)v = -(\lambda v) = \lambda(-v)\]
\[stel:w=0\]
\[(\lambda)(v+w) = \lambda(v) + \lambda(w) = \lambda(v) + \lambda(0) = \lambda(v) = (\lambda v) \]
\[\text{In punt 2 werd gesteld dat het tegengestelde element van v = -v}\]
\[Dus: -\lambda v = tegengstelde \cdot \lambda v\]
\[(-\lambda)v = -(\lambda v) = \lambda(-v) \]

\section{Opdrachten}
\subsection{3.9}
Neem aan dat $\lambda \cdot v = 0$ voor $\lambda \in \mathbb{R}$ en $v \in V$.\\
Er zijn dan twee mogelijkheden:\\
\begin{enumerate}
\item $\lambda = 0$ dan is het in orde.
\item $\lambda \neq 0$
\begin{align*}
v = 1\cdot v \tag{co\"efficient}
\\
= \frac{\lambda}{\lambda}\cdot v
\\
= \frac{1}{\lambda}(\lambda \cdot v) \tag{gemegde associativiteit}
\\
= \frac{1}{\lambda}(0) \tag{lemma 3.8.1}
\\
= 0
\end{align*}

\end{enumerate}
\subsection{3.21}
Om aan te tonen dat $U_1 + U_2$ deelruimten zijn van $V$ dan moeten we de drie eigenschappen van een deelruimte aantonen:
\begin{enumerate}
\item We moeten aantonen dat $0 \in U_1 + U_2$.\\
We weten dat $U_1$ en $U_2$ deelruimten zijn van $V$.\\
Dus $0 \in U_1$ en $0 \in U_2$ samen met het feit dat $0 = 0 + 0$ volgt dat $0 \in U_1 + U_2$.

\item We moeten aantonen $\forall x,y \in U_1 + U_2$ geldt: $x + y \in U_1 + U_2$.\\
Veronderstel dat twee willekeurige vectoren $x$ en $y \in U_1 + U_2$ bestaan.\\
Dan volgt uit de definitie van $U_1 + U_2$ dat er twee vectoren $x_1$ en $y_1 \in U_1$ en $x_2$ en $y_2 \in U_2$ bestaan zodat $x = x_1 + x_2$ en $y = y_1 + y_2$.\\
Hieruit volgt:
$$x + y = (x_1 + x_2) + (y_1 + y_2) = (x_1 + y_1) + (x_2 + y_2)$$
Omdat $x_1, y_1 \in U_1$ en $U_1$ is een deelruimte van V, $x_1 + y_1 \in U_1$.\\
Omdat $x_2, y_2 \in U_2$ en $U_2$ is een deelruimte van V, $x_2 + y_2 \in U_2$.\\
Nu hebben we aangetoond dat $x+y$ de som is van een vector in $U_1$ en een vector in $U_2$. 
Dus $x + y \in U_1 + U_2$ door de definitie van $U_1 + U_2$ en aangezien $x$ en $y$ willekeurig waren geldt dit voor alle $x,y \in U_1 + U_2$.

\item We moeten aantonen dat $\forall x \in U_1 + U_2$ en $\forall r \in \mathbb{R}$ geldt: $rx \in U$.

Veronderstel dat een willekeurige $x \in U_1 + U_2$ en $r \in \mathbb{R}$ bestaan. Dan volgt uit de definitie van $U_1 + U_2$ dat er een $x_1 \in U_1$ en $x_2 \in U_2$ bestaan zodat $x = x_1 + x_2$.\\
Hieruit volgt:
$$rx = r(x_1+x_2) = rx_1+rx_2$$
Omdat $x_1 \in U_1$ en $U_1$ is een deelruimte van V, $rx_1 \in U_1$.\\
Omdat $x_2 \in U_2$ en $U_2$ is een deelruimte van V, $rx_2 \in U_2$.\\
Nu hebben we aangetoond dat $rx$ de som is van een vector in $U_1$ en een vector in $U_2$. 
Dus $rx \in U_1 + U_2$ door de definitie van $U_1 + U_2$ en aangezien $x$ en $r$ willekeurig waren geldt dit voor alle $r \in \mathbb{R}$ en $x \in U_1 + U_2$.
\end{enumerate}
\subsection{3.24}

1) 
Neem \\ 
$$U_1 = \{(x,0,0)\} $$
$$U_2 =  \{ (0,y,0)\} $$
$$U_3 = \{ (x,y,0)\} $$
2) ???

\subsection{3.51}
$U+W$ is de deelruimte van $R[X]_{\le4}$ waarbij $a_3 = a_4$.
\[U+W = \{a_0 + a_1 X + a_2 X^2 +a_3 X^3 + a_4 X^4 | a_3 = a_4\}\]
Een basis van $U$ is simpelweg $\beta_U = \{1,X,X^2\}$. Een basis van $W$ is $\beta_W = \{X+X^2,X^3+X^4\}$. Een basis voor $U\cap W$ is $\beta_{U\cap W} = \{X+X^2\}$. Tenslotte is $\beta_{U+W} = \{1,X,X^2,X^3+X^4\}$ een basis van $U+W$. We verifi\"eren nu de dimensie stelling\footnote{Zie stelling 3.49 p 114.}.
\[
dim(U+W) + dim(U\cap W) = dimU+dimW
\]
\[
4 + 1 = 3+2
\]
Dit ziet er juist uit.

\subsection{3.59}
\subsubsection*{Te Bewijzen}
\[
\left\lbrace
\begin{array}{c c}
a_1x_1 + b_1x_2 + c_1x_3 + d_1x_4 &= 0 \\
a_1x_1 + b_2x_2+ c_2x_3 + d_2x_4 &= 0 \\
a_1x_1 + b_3x_2+ c_3x_3 + d_3x_4 &= 0 \\
\end{array}
\right.
\]
Het bovenstaande stelsel heeft een niet-triviale oplossing. (Oneindig veel niet-triviale oplossingen zelfs.)
\subsubsection*{Bewijs}
Het originele stelsel ziet er als volgt uit in matrixvorm.
\[
\begin{pmatrix}
a_1 & b_1 & c_1 & d_1\\
a_2 & b_2 & c_5 & d_2\\
a_3 & b_3 & c_3 & d_3\\
\end{pmatrix}
\cdot
\begin{pmatrix}
x_1\\ x_2\\x_3
\end{pmatrix}
= \vec{0}
= 
\begin{pmatrix}
a & b & c & d
\end{pmatrix}
\cdot
\begin{pmatrix}
x_1\\ x_2\\x_3
\end{pmatrix}
\]
Beschouwen we vectoren $(a_1,a_2,a_3)$, $(b_1,b_2,b_3)$, $(c_1,c_2,c_3)$ en $(d_1,d_2,d_3)$. Volgens het Lemma van Steinitz\footnote{Zie Stelling 3.32 p 104} is elke verzameling van vectoren in $\mathbb{R}^3$ met meer dan drie elementen lineaire afhankelijkheid. Dit geldt dus ook voor onze vier beschouwde vectoren. Als we nu stellen dat minstens \'e\'en van de vectoren samengesteld wordt uit de anderen, dan kunnen we onze onbekenden $x_1$, $x_2$, $x_3$ en $x_4$ zo kiezen dat we het tegengestelde van de samengestelde (lineair afhankelijke) vector(en) vormen uit het lineair onafhankelijk en (eventueel deels) voortbrengend deel. Stel dat $d$ lineair afhankelijk is van $a, b$ en $c$ (welke vector dit is maakt niet uit omwille van de commutativiteit van de optelling in $\mathbb{R}$.), dan ziet dit er uit als volgt.
\[
\left\lbrace
\begin{array}{c c}
-d_1x_4 + d_1x_4 &= 0 \\
-d_2x_4 + d_2x_4 &= 0 \\
-d_3x_4 + d_3x_4 &= 0 \\
\end{array}
\right.
\]
Dan is voldaan aan ons homogeen stelsel omdat beide elkaar zullen opheffen. Deze oplossing van het homogeen stelsel is niet triviaal omdat een eigenschap van lineaire onafhankelijkheid\footnote{Zie Propositie 2.26 p 101} zegt dat de co\"fficienten $x_1,x_2,x_3$ niet nul mogen zijn.
Deze redenering geldt voor elke keuze van $x_4\in \mathbb{R}$, dus er zijn oneindig veel triviale oplossingen.

\end{document}
